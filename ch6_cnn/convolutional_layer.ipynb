{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243e9b60",
   "metadata": {},
   "source": [
    "# 卷积层\n",
    "图像卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397665d6",
   "metadata": {},
   "source": [
    "## 互相关运算\n",
    "输出矩阵的形状为\n",
    "\n",
    "$(n_w-h_w+1)\\times (n_h-k_h+1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1191d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from d2l import torch as d2l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30389b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X,K):\n",
    "    '''互相关运算'''\n",
    "    h,w = K.shape\n",
    "    Y = torch.zeros(X.shape[0] - h + 1,X.shape[1] - w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h,j:j+w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3c333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证互相关运算\n",
    "X = torch.tensor([[0.0,1.0,2.0],[3.0,4.0,5.0],[6.0,7.0,8.0]])\n",
    "K = torch.tensor([[0.0,1.0],[2.0,3.0]])\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66881e",
   "metadata": {},
   "source": [
    "## 卷积层\n",
    "1. 进行输入与卷积核的互相关运算\n",
    "2. 加上偏置项\n",
    "3. 得到最后输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f8e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init__()\n",
    "        # 初始化卷积核权重和标量偏置\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self,X):\n",
    "        return corr2d(X,self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08704027",
   "metadata": {},
   "source": [
    "# 图像中目标的边缘检测\n",
    "卷积层的一个简单应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ff9cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(6,8)\n",
    "X[:,2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b18a5",
   "metadata": {},
   "source": [
    "构造一个 $1\\times 2$ 的卷积核，进行互相关运算时，若是水平相邻的两个元素相同，则得到结果为0，否则非0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5fd400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0,-1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bcc96",
   "metadata": {},
   "source": [
    "结果中 $1$ 代表白到黑的边缘（因为白色的RGB值更大，结果为正）,$-1$ 代表黑到白的边缘，其他为 $0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c55686de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X,K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95b80b",
   "metadata": {},
   "source": [
    "将输入转置，再进行互相关运算，此时水平边缘变成了垂直边缘，而卷积核只能检测水平的，无法检测垂直边缘，结果全为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f106661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(),K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e8f80",
   "metadata": {},
   "source": [
    "# 学习卷积核\n",
    "对于更加复杂的任务，难以手动指定卷积核，需要通过学习训练的方法。\n",
    "1. 初始化卷积核权重\n",
    "2. 更新卷积核参数\n",
    "   1. 先前向传播得到输出结果\n",
    "   2. 计算结果与真实 $\\bf Y$ 之间的 `MSE` \n",
    "   3. 反向传播，利用梯度对卷积核参数进行更新\n",
    "\n",
    "（忽略偏置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c329e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 12.299\n",
      "epoch 4, loss 2.172\n",
      "epoch 6, loss 0.409\n",
      "epoch 8, loss 0.087\n",
      "epoch 10, loss 0.022\n"
     ]
    }
   ],
   "source": [
    "# 构造二维卷积层，1个channel，卷积核形状(1，2)\n",
    "conv2d = nn.Conv2d(1,1,kernel_size=(1,2),bias=False)\n",
    "\n",
    "# 二维卷积层使用思维输入和输出（batch_size, channel, height, width）\n",
    "X = X.reshape(1,1,6,8)\n",
    "Y = Y.reshape(1,1,6,7)\n",
    "lr = 3e-2\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    #print(Y_hat.shape)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    \n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f\"epoch {i+1}, loss {l.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e20e5",
   "metadata": {},
   "source": [
    "查看当前卷积核权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed458e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9937, -0.9705]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e0e29",
   "metadata": {},
   "source": [
    "这与之前手动定义的卷积核很接近"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc6128",
   "metadata": {},
   "source": [
    "# 填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "062d525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3996,  0.3685,  0.5199,  0.3312,  0.4455,  0.3291,  0.6515,  0.7110],\n",
       "        [ 0.6548,  0.7531,  0.9232,  0.6899,  0.5685,  0.3645,  1.0758,  0.7272],\n",
       "        [ 0.7727,  0.6601,  0.8418,  0.5716,  0.6020,  0.7242,  0.8847,  0.4896],\n",
       "        [ 0.7219,  0.6256,  0.7898,  0.4810,  0.7979,  0.9729,  1.0473,  0.5666],\n",
       "        [ 0.9236,  0.3687,  0.5537,  0.6873,  0.4901,  0.3966,  0.9801,  0.6681],\n",
       "        [ 0.6594,  0.2367,  0.8908,  0.9591,  0.7761,  0.7799,  0.5310,  0.2995],\n",
       "        [ 0.5597,  0.7099,  0.7016,  0.7472,  0.7089,  0.9325,  0.9890,  0.3391],\n",
       "        [ 0.5228,  0.3182,  0.3597,  0.5453,  0.0543,  0.4066,  0.4735, -0.0270]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comp_conv2d(conv2d,X):\n",
    "    X = X.reshape((1,1) + X.shape) # (1,1)指批量大小和通道数\n",
    "    Y = conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:]) # 省略前两维，批量大小和通道数\n",
    "\n",
    "# 这里的padding=1指每边都填充了1行或1列，因此总共添加了2行2列\n",
    "conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1)\n",
    "X = torch.rand(size=(8,8))\n",
    "comp_conv2d(conv2d,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edba186",
   "metadata": {},
   "source": [
    "卷积核高度和宽度不同时，可以填充不同的高度和宽度，使输入和输出具有相同形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64678c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1131,  0.2865,  0.1526,  0.5786,  0.3448,  0.3066, -0.0010,  0.4695],\n",
       "        [ 0.1016,  0.6861,  0.2926,  0.4483,  0.3911,  0.6994,  0.2409,  0.3696],\n",
       "        [ 0.1683,  0.8271,  0.3489,  0.5280,  0.2540,  0.6718,  0.9124,  0.4339],\n",
       "        [ 0.1209,  0.7737,  0.5261,  0.6060,  0.3929,  0.4872,  0.7636,  0.6328],\n",
       "        [ 0.1418,  0.7242,  0.4915,  0.4857,  0.8019,  0.5707,  0.6731,  0.6340],\n",
       "        [ 0.3633,  0.3315,  0.5328,  0.6310,  0.6902,  0.5789,  0.5479,  0.7128],\n",
       "        [ 0.2413,  0.4409,  0.5399,  0.4978,  0.7804,  0.6827,  0.3848,  0.4191],\n",
       "        [ 0.3089,  0.4131,  0.5471,  0.4439,  0.5613,  0.6888,  0.4876,  0.3602]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d27bd6",
   "metadata": {},
   "source": [
    "# 步幅\n",
    "- 高效计算\n",
    "- 缩减采样次数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df03e9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5f798ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3122, -0.0341],\n",
       "        [-0.4073, -0.4644]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4))\n",
    "comp_conv2d(conv2d,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147c872a",
   "metadata": {},
   "source": [
    "# 多输入通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a27324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X,K):\n",
    "    return sum(d2l.corr2d(x,k) for x,k in zip(X,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9231830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X,K)\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fbdd2",
   "metadata": {},
   "source": [
    "# 多输出通道\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e60140",
   "metadata": {},
   "source": [
    "为每个输出通道建立 $c_i\\times k_h\\times k_w$ 的卷积核，这样卷积核就是四维张量 $c_o\\times c_i\\times k_h\\times k_w$ ，在互相关运算中，每个输出通道先获取所有输入通道，再以对应该通道的卷积核计算出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8dfacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X,K):\n",
    "    return torch.stack([corr2d_multi_in(X,k) for k in K],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7e3c0",
   "metadata": {},
   "source": [
    "通过将卷积核 $K$ $K+1$ $K+2$ 连接起来，构成了三个输出通道的卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aedc73f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K,K+1,K+2),0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fee4f4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ea2ad",
   "metadata": {},
   "source": [
    "# $1\\times 1$ 卷积层\n",
    "- 改变输出通道数，元素值不变\n",
    "- 等价于全连接层，没有实现卷积的“提取相邻像素的相关特征”的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e5ead85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_11(X,K):\n",
    "    c_i,h,w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape(c_i,h*w)\n",
    "    K = K.reshape(c_o,c_i)\n",
    "    # 全连接层的矩阵乘法\n",
    "    Y = torch.matmul(K,X) # K的列等于X的行，从reshape可知\n",
    "    # 输入X的通道数是3，输出Y的通道数是2\n",
    "    return Y.reshape(c_o,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03011215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0,1,(3,3,3))\n",
    "K = torch.normal(0,1,(2,3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1215ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 3]), torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = corr2d_multi_in_out_11(X,K)\n",
    "Y2 = corr2d_multi_in_out(X,K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6\n",
    "Y1.shape,Y2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af27e961",
   "metadata": {},
   "source": [
    "# 汇聚层 `Pooling`\n",
    "作用：\n",
    "- 降低卷积层对位置的敏感性\n",
    "- 降低对空间降采样表示的敏感性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b368850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X,pool_size,mode=\"max\"):\n",
    "    p_h,p_w = pool_size\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1,X.shape[1] - p_w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == \"max\":\n",
    "                Y[i,j] = X[i:i+p_h,j:j+p_w].max()\n",
    "            elif mode == \"mean\":\n",
    "                Y[i,j] = X[i:i+p_h,j:j+p_w].mean()\n",
    "                \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e0092bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0,1.0,2.0],[3.0,4.0,5.0],[6.0,7.0,8.0]])\n",
    "pool2d(X,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2204db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X,(2,2),mode=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed0a04",
   "metadata": {},
   "source": [
    "## [填充与步幅]\n",
    "改变输出形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8d0020a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X的样本数和通道数都为1\n",
    "X = torch.arange(16,dtype=torch.float32).reshape(1,1,4,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f19dd4",
   "metadata": {},
   "source": [
    "使用内置的二维最大汇聚层，演示填充与步幅的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ee58fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb1d696c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2,3),stride=(2,3),padding=(0,1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff33bf",
   "metadata": {},
   "source": [
    "## [多个通道]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319d448",
   "metadata": {},
   "source": [
    "汇聚层对每个通道单独运算，不求和，输出通道数与输入通道数相同"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94785cb1",
   "metadata": {},
   "source": [
    "在通道维度上连接X与X+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b84b0c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X,X+1),1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78e978fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73c9bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3,padding=1,stride=2)\n",
    "pool2d(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
