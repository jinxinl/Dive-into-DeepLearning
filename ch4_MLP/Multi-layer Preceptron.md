# `Multi-layer Preceptron(MLP)`

[TOC]

##  多层感知机 `(Multi-layer Preceptron，MLP)`

本章中第一次正式介绍深度神经网络，`MLP` 是最简单的深度网络，当前层神经元与上一层完全相连，输出值也与下一层完全相连，影响下一层神经元。

**隐藏层的重要性 `Hidden layer`**

在现实世界中，并不是所有关系都能够用线性关系表达，甚至绝大部分问题都是非线性问题，因此线性模型在解决问题时存在很大的局限性。

例如图像分类问题，判断猫狗图像，线性问题中某一特征值 $x_i$ 的增大必然会导致结果 `y_i` 的增大（正系数）或减小（负系数），也就是特征与结果之间是单调的关系，对应地，在图像中某一处的像素增大，却不能表示这幅图像是猫还是狗。*对线性模型的依赖对应与一个隐含的假设：区分猫和狗的唯一要求是评估单个像素的强度* ，但是只要图像进行翻转，在图像倒置而类别保留的情况下，结果必然不正确，我们需要考虑的并不是单个位置的像素强弱对最终结果的影响，而是考虑像素之间的相关作用。

因此，在深度网络中，引入 **隐藏层** ，考虑特征之间的相互作用，并在此基础上建立一个线性模型，克服前面提到的 `linear regression` 与 `softmax regression` 以独立的视角看待输入特征的局限性，捕捉特征之间的关系。

**`MLP`**

- 架构：我们可以通过在网络中加入 `n` 层全连接层，将其堆叠在一起，用前 `L-1` 层看作表示，第 `L` 层看作线性预测器

  类似下图，一共两层，有4个输入、5个隐藏单元、3个输出，输入单元、隐藏单元、输出单元之间相互连接、相互影响

  <img src="C:\Users\xinling\AppData\Roaming\Typora\typora-user-images\image-20250228223022606.png" alt="image-20250228223022606" style="zoom:67%;" />

- 局限：由于全连接的特点，导致参数开销很大，对计算和存储都有挑战性，需要平衡参数节约与模型有效性

**激活函数**

- 加入隐藏层后，每层的输入输出如下：
  $$
  {\bf H=XW^{(1)}+b^{(1)}}
  $$

  $$
  \bf O=HW^{(2)}+b^{(2)}
  $$

- 

​	在前面的 `MLP` 中，虽然堆叠了若干个隐藏层，但是层与层之间的变换仍是仿射变换，仿射变换的嵌套	仍是仿射变换，即通过代入 $\bf H$ 可得 $\bf O$ ：	
$$
\bf O=XW^{(1)}W^{(2)}+b^{(1)}W^{(2)}+b^{(2)}=XW+b
$$
​	所以虽然加入了一层隐藏层，但仍然等价于单层网络。

- 为了发挥多层网络的优势，还需要额外一个关键因素——**激活函数** ，它通常是一个非线性函数，将当前层的输出进行非线性变换，这样就可以有效防止 `MLP` 退化为线性模型
  $$
  {\bf H}=\sigma( {\bf XW^{(1)}+b^{(1)}})
  $$

  $$
  \bf O=HW^{(2)}+b^{(2)}
  $$

- 在构建深度网络时，一般通过堆叠如上的 $\bf H$ 来提高模型的表达能力（捕捉非线性关系等更加复杂的关系）

**通用近似定理**

理论上来说，一个单隐层网络，通过很好地训练和学习，能够对任意函数建模。

类比编写一个C语言代码，理论上可以表达任意可计算程序，然而实际上如何相处符合要求的程序才是难点。神经网络也是如此，虽然单隐层网络理论上可以对任意函数建模，但是如何学习才是难点。

虽然有通用近似定理，但并不代表应该尝试使用单隐层网络来解决所有问题，实际上可以通过增加模型深度，来逼近函数。

*增加深度 v.s. 增加广度*

**激活函数**

非线性、可微。常用激活函数如下：

- $ReLU$ 函数
  $$
  ReLu(x) = max(x,0)
  $$
  对于输入，设置活性值为0，只存在通过与非通过，是分段线性的。

  当输入恰好为0时，不可导，此时默认使用左导数，即0，但是这种情况一般可忽略，因为输入永远不可能是0。

  > 如果微妙的边界条件很重要，我们很可能是在研究数学而非工程。

  使用 $ReLU$ 的原因是：（1）实现简单，计算效率非常高，并且在预测任务上表现良好（2）求导表现很好，要么让参数消失，要么让参数通过，这使得优化表现得很好，减轻了梯度消失问题。

  $ReLU$ 有许多变体，通常是放松对负数通过的限制。

- $sigmoid$ 函数
  $$
  f(x)=\frac{1}{1+e^{-x}}
  $$
  平滑、可微的阈值单元函数近似，当输入 $x$ 接近于0时，$sigmoid$ 接近线性变换。

  把输入 $x$ 压缩到 $(0,1)$ 区间上
  $$
  f'(x)=f(x)[1-f(x)]
  $$
  
- $tanh$ 函数（双曲正切）
  $$
  f(x)=\frac{1-e^{-2x}}{1+e^{-2x}}
  $$
  当输入在0附近时，$tanh$ 函数接近线性变换

  把输入 $x$ 压缩到 $[-1,1]$ 区间上，关于原点中心对称
  $$
  f'(x)=1-f(x)^{2}
  $$
  

## 模型选择 过拟合 欠拟合

**模型选择**

研究的目的是发现数据间潜在的通用规律，也就是所谓 *模式* 。只有当模型真正发现了一种泛化模式时，才会做出有效预测。

当模型在训练数据上的拟合比在潜在分布中的拟合更加接近时，叫做 **过拟合** ，通俗来讲，过拟合就是当模型参数量与训练数据量不匹配时出现的情况，因为模型的学习能力随着参数量的增加而提高，但是训练数据却十分有限，那么模型就会捕捉到训练数据之间个性的特征，而不是通用的特征，导致训练集上表现优异而测试集上表现不佳，对抗过拟合的技术叫做 **正则化** 。**欠拟合** ，顾名思义，就是模型连训练集的数据都没有学习得很好。

**训练误差 泛化误差**

在进一步了解 **过拟合与欠拟合** 前，还需要知道两个基本概念：训练误差、泛化误差。

**训练误差**指的是模型在训练数据上的误差，**泛化误差** 指的是模型在未见过的新数据上的误差，这里的新数据是从原始数据分布中抽取出的新样本（训练集测试集的总的数据分布是一样的）。**过拟合** 就是训练误差小，但泛化误差大，**欠拟合** 是训练误差大，泛化误差也大

**统计学习理论**

- 独立同分布假设：假设训练数据与测试数据都是从同一个分布中随机抽取得到的，数据点之间相互独立。这个假设意味着对数据的抽取是“无记忆性”的，也就是与抽取到的数据间的顺序无关。然而，在现实生活中，这个假设大部分情况下都不满足，因为要求的条件太高了且很难验证。但是有些时候轻微地违反独立同分布假设也没关系，如机器翻译等

**模型复杂性**

一般，拥有更多参数的模型可以看成是复杂模型，参数的数量意味着模型的学习能力，若是模型参数量很大而

数据不足，或导致过拟合。

影响模型泛化的因素：

- 可调整的参数量
- 采样用的值的范围：如权重范围
- 训练样本的数量

**验证集**

模型在训练阶段使用训练集更新参数，在测试阶段使用测试集评估性能，然而：

（1）过拟合了训练数据可以通过测试集表现看出，但是过拟合测试数据要怎么判断呢？

（2）K折交叉验证 / 留一法



## 权重衰减 `Weight decay`

解决过拟合问题可以通过（1）收集更多数据（2）正则化技术

权重衰减是最广泛使用的正则化技术之一，与之前介绍的范数有密切关联，通常也被叫做 $L_2$ 正则化。

- 原理：通过函数与0的距离来衡量函数的复杂度。关键在于如何测量函数和0之间的距离
  - 使用范数作为度量：如 $\|w\|^2$ ，为了保证权重尽可能小，可以将其作为惩罚项加入损失函数中，通过系数 $\lambda$ 来控制惩罚的强弱，这样的带有对权重的惩罚项的 *线性模型* 叫做 **岭回归 (`Ridge reression`)**。【$L_1$ 正则化线性模型叫做 **`Lasso regression`**】
- 使用 $L_2$ 正则化而不是 $L_1$ 正则化的理由：
  - $L_2$ 正则化对权重向量的大分量施加了巨大的惩罚，得到的模型更偏向于权重在所有特征上均匀分布，在实践中，这可能使它们对单个变量的观测误差更稳定。
  - $L_1$ 正则化会导致模型的权重集中在一小部分特征上，其他特征的权重为0，这叫 **特征选择** ，也正是因为如此，$L_1$ 正则化可以用于降维
- “权重衰减” 的含义：在更新 $\bf w$ 的同时希望将 $\bf w$ 的值缩小到0。仅考虑惩罚项，在更新参数时也会相应地让参数越来越小，并且 $\|\bf w\| ^2$ 是连续可微的函数，提供了一种连续的机制来调整函数的复杂度，惩罚项系数$\lambda$ 的值越大，对应地约束就越大。
- 通常，*输出层* 偏置项 $\bf b$ 不会被正则化。



## 暂退法 `Dropout` 

过拟合中存在的问题是过度关注少数的、个性的虚假关联，我们更希望模型深度挖掘特征之间的潜在关联，即将权重分散到许多特征中。

通常而言，线性模型较为简单，一般不会产生过拟合，但是这种可靠性是有代价的，线性模型只考虑到特征对结果的直接影响，没有考虑特征之间的相互作用，即特征组合会对结果带来影响。所以说，线性模型是泛化性较高，但灵活性较低。

**泛化性和灵活性**

泛化性和灵活性之间的权衡也叫 **偏差-方差权衡 `(bias-variance tradeoff)`** 。

线性模型有很高的偏差，只能代表一小类函数，但是方差很低，对于不同的随机数据可以给出相似的结果。

深度神经网络而与之相反，它的偏差低，方差高：能够拟合很多复杂函数，并且对于不同的随机数据可以给出更加灵活的结果。因为神经网络并不局限于单独查看每个特征，而是学习特征之间的交互联系，然而，由于深度神经网络的复杂性，在早期数据并不充分时，模型的过拟合问题很严重。

**扰动的稳健性**

- “好”的模型：能够在未知数据上有很好表现的，就是“好”的模型。经典理论认为：为了缩小训练和测试性能的差距，应该以简单的模型为目标，也就是 “奥卡姆剃刀原理”。然而 “简单” 的含义是什么？

  - 参数量，可以使用参数的范数作为度量，比如权重衰减的原理
  - 平滑性，函数不应该对输入中微小的变化敏感，理论已经证明了“函数光滑”与”输入的随机噪声具有适应性“是等价的。

- 原理：前向传播时，在计算下一层之前，向当前层加入噪声，这样在计算当前层时是混有噪声的。之所以叫“暂退法”，是因为从表面上看时在训练过程中随意“丢弃”一些神经元。

  > 原论文中使用了有性繁殖的类比，神经网络过拟合与每一层都依赖于激活值相关，这种情况叫做“共适应性”，而作者认为暂退法会破坏共适应性，就像有性繁殖会破坏共适应的基因一样。

- 关键：如何注入噪声，一种方法是以无偏向的方式注入，这样在固定其他层时，每一层的期望等于没有噪音时的值。因为当训练深度网络时，在每一层中注入噪声相当于在输入-输出上增加平滑性。可以这么理解，在训练过程中加入噪声，模型学习的数据中混有随机的、轻微的扰动，那么在不断地更新优化中，模型的表现能力通过参数更新得到提高，抗干扰能力也在与噪声的对抗中得到提高，对应的平滑性也就更强。

  在标准暂退法中，从标准正态分布中采样噪声，并加入到输入中
  $$
  \epsilon\sim\mathcal{N}(0,1),x'=x+\epsilon
  $$
  期望 $E(x')=E(x)$ 。

  在标准暂退法正则化中，通过按保留的节点的分数进行规范化来消除每一层的偏差，也就是，每个中间活性值 $h$ 以暂退概率 $p$ 由随机变量 $h'$ 替换，公式如下：
  $$
  h'=\begin{cases} 0 &\text{概率为 }p\\\frac{h}{1-p} &\text{其他情况}
  \end{cases}
  $$
  最后得到的期望值保持不变，即 $E(h')=h$

- 在实践中，使用暂退法得到的网络可以看成是原网络的一个子集，在前向传播时丢弃的神经单元，在反向更新时梯度也会对应消失，这样，输出层的计算就不会过度依赖于某一个权重



## 反向传播 `backprop`

**前向传播**

计算每层输出值：
$$
\bf z=W^{(1)}x\\
\bf h=\phi(z)\\
\bf o=W^{(2)}h\\
\bf L=l(o,y)\\
\bf s=\frac{\lambda}{2}(\|W^{(1)}\|^2_F+\|W^{(2)}\|^2_F)\\
\bf J=L+s
$$
**反向更新**

利用链式法则计算每个中间变量和参数的梯度。

在训练神经网络时，前向传播和反向更新是相互依赖的，计算顺序相反。前向传播中，正则化项 $s$ 的计算依赖于 $\|W^{(1)}\|^2_F+\|W^{(2)}\|^2_F$ 的当前值，它们是由优化算法根据最新的反向传播给出。在反向传播时，$\|W^{(1)}\|^2_F+\|W^{(2)}\|^2_F$ 是由前向传播给出的隐藏变量的值决定。

由于在训练过程中反向传播需要重复利用前向传播的中间值，所以需要对这些中间值进行存储，以免重复计算，造成计算效率低下。而这些中间值的存储会带来更大的空间开销，这也是为什么训练比推理要占用更多的显存。

此外，中间值的大小与网络层数和批量大小成正比，因此当使用更大批量或网络层数加深时，需要更多的显存。



## 数值稳定性和模型初始化

**数值稳定性**

在训练神经网络时，**梯度爆炸** 和 **梯度消失** 是经典的问题，因为对于深层的网络，在反向传播中利用链式法则求得某个中间变量的梯度值，但是链式法则需要使用连乘计算，如果矩阵太大，那么连乘会导致梯度大到爆炸，如果矩阵太小，那么连乘会导致结果趋近于0。用极端例子来看，大于1的数字在经过无限多轮连乘后会趋近于正无穷，小于1的数字在经过无限多轮连乘后会趋近于0。

神经网络更新参数是减去学习率与对应梯度的乘积，（1）若是出现了梯度爆炸，那么容易导致震荡，训练不稳定（2）若是出现了梯度消失，那么参数前后改变不大，更新缓慢，会出现训练停滞不前的情况。

【上述提到的 $sigmoid$ 函数非常容易造成梯度消失，因为它的导数在输入很大或是很小时，都会接近于0，导致整个乘积的梯度趋近于0。因此后来人常用 $ReLU$ 函数作为激活函数，虽然在神经科学上没有 $sigmoid$ 看起来那么合理，但是效果好，简单，收敛快且稳定。】

**打破神经元的对称性**

在隐藏层的神经单元中，实际上每个神经单元间并没有特殊区别，对第一层权重和第二层权重分别进行重排列，也能够得到相同的函数，因此 **每一层的隐层单元之间具有对称性** 。因此，如果将同一层的隐藏单元全部初始化为常数 $c$ ，采用相同的输入和参数，通过相同的激活函数，得到相同的输出，反向传播时计算的梯度也相同，基于梯度的迭代也采用相同的值，那么这样的迭代永远无法打破对称性，无法实现网络的表达力，隐藏层退化成一个隐藏单元。小批量随机梯度下降无法打破这种对称性，但是暂退法通过随即丢弃神经元可以打破。

**参数初始化**

参数初始化对于神经网络的训练起着重要作用，（1）对保持数值稳定至关重要，（2）并且与非线性激活函数的选择可以有趣地结合在一起。

选择哪个激活函数，如何初始化参数会对收敛速度甚至能否收敛产生影响，并且参数初始化的方案也会直接影响参数对称性（希望是能够打破），糟糕的方案有时会导致梯度爆炸或梯度消失。

- 默认初始化：参数从标准正态分布中随机采样
- $Xavier$ 初始化：参数从 $\mathcal{N}(0,\frac{2}{n_{in}+n_{out}})$ 中采样，$n_{in}$ 与 $n_{out}$ 分别指该层的输入和输出数量



## 环境和分布偏移

数据从哪里来（数据分布），最终如何处理模型的输出。开发人员会拥有一些数据且急于开发模型，但往往会忽略数据分布的问题：

- 在测试集上模型也能够表现出色，但是一旦数据分布发生改变，模型部署时就会出现灾难性错误
- 有时模型部署本身就像是扰乱数据分布的催化剂：比如开发一个贷款申请人违约风险模型，预测谁会违约，但是模型学习到的是违约与否与申请人的鞋子有关，穿牛津鞋的判断为不会违约，穿运动鞋的判断为会违约，一旦顾客开始理解这种行为，就会有越来越多人申请时穿牛津鞋 *（改变数据分布的催化剂）* ，不久后，所有人都穿牛津鞋，但信用度却没有提高。**通过将基于模型的决策引入环境，我们可能会破坏模型** 。

**分布偏移的类型**

如果训练数据的分布与测试数据的分布毫无关系，那么使用训练数据学习出一个在测试集上表现良好的分类器是不可能的。

- **协变量偏移 `covariate shift`**：输入的分布可能随时间而改变，但标签函数没有改变。这个问题是由协变量分布（特征分布）的变化而产生的。例如，输入数据是关于“猫-狗”的真实图片，但是测试时是对“猫-狗”的卡通图片进行分类。

- **标签偏移 `label shift`**：标签函数可能随时间而改变，但输入的分布没有改变，与协变量偏移刚好相反。这里假设的是标签边缘概率 $P(y)$ 可以改变，但是类别条件分布 $P(y|x)$ 不会改变。例如预测患者得了某一种疾病，我们可以根据已出现的病症进行判断，虽然该病的发生概率可能随着时间而变化。

  ​	标签偏移和协变量偏移是可以同时成立的，此时使用基于标签偏移假设的方法通常更加有利，因为这些方法倾向于包含看起来像标签（通常是低维）的对象，而不是像输入（通常是高维）的对象

- **概念偏移 `concept shift`**：比如随着社会发展，有一些名词的概念也发生了变化，在训练翻译模型时，可能会受到概念偏移的影响，所以最好可以利用在时间或空间上逐渐发生偏移的知识。

**非平稳分布**

分布变化缓慢且模型没有得到充分更新时，如：计算广告的模型，过滤垃圾邮件的模型，产品推荐系统

**分布偏移纠正**

训练时计算的输出值和真实值之间的损失叫做 **经验风险** ，即整个训练数据上的平均损失，它是为了近似 **真实风险** ，真实风险是真实数据分布中所有数据的总体损失的期望。然而在实践中不可能对所有数据进行计算，也无法获得，因此，**经验风险最小化** 被提了出来，它是一种实用的机器学习策略。

- **协变量偏移纠正**：训练数据与测试数据分布不一致，但是标签函数不变，但是需要注意到，依赖性假设不变，即 $p(y|x)=q(y|x)$ ，这样就可以根据每条数据来自正确分布与错误分布的概率之比，来重新衡量每条数据的权重。
  $$
  \iint l(f({\bf x}),{\bf y})p({\bf y|x})p({\bf x})d{\bf x}d{\bf y}=\iint l(f({\bf x}),{\bf y})q({\bf y|x})q({\bf x})\frac{p(\bf x)}{q(\bf x)} d{\bf x}d{\bf y}
  $$
  这里的 $\beta_i=\frac{p({\bf x_i})}{q({\bf x_i})}$ 就是数据的权重，使用加权经验风险最小化来训练模型
  $$
  \min_f\frac{1}{n}\sum_{i=1}^{n}\beta_il(f({\bf x_i}),{\bf y_i})
  $$
  由于不知道 $\beta_i$ ，因此需要估计，我们需要知道真实的分布和训练集，前者通过访问测试数据获取，后者通过人工合成得到，但有一种方法能够获得与原始方法基于一样好的效果——`logistic regression` 。我们训练一个分类器，判断数据是来自真实分布还是训练集。纠正协方差偏移的算法如下：

  1. 获取数据集
  2. 用 `logistic regression` 训练出一个分类器，得到函数 `h` ，判断数据是来自真实分布还是训练集
  3. 使用 $\beta_i=e^{h(x_i)}$ 对训练数据进行加权
  4. 使用权重 $\beta_i$ 进行训练

  上述算法依赖于假设：需要目标分布中的每个数据在训练时出现的概率非0。否则对于真实分布中出现概率大于0但训练中出现概率为0的数据，得到的权重将会是无穷大。

- **标签偏移纠正** ：将上述的 $\beta_i$ 的公式改为 $\beta_i=\frac{p({\bf x_i})}{q({\bf y_i})}$ ，对应的风险计算转化为

$$
\iint l(f({\bf x}),{\bf y})p({\bf x|y})p({\bf y})d{\bf x}d{\bf y}=\iint l(f({\bf x}),{\bf y})q({\bf x|y})q({\bf y})\frac{p(\bf y)}{q(\bf y)} d{\bf x}d{\bf y}
$$

​	使用性能好的分类器（基于训练集训练），以及验证集（来自训练分别）计算混淆矩阵 $C_{k \times k}$ ，其中每列对应标签类别，每行对应模型预测类别，$c_{ij}$ 代表验证集中，真实标签为 $j$ ，而模型预测标签为 $i$ 的样本所占比例。

。。。。。。。
